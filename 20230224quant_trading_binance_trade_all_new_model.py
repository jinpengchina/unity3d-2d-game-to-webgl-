# -*- coding: utf-8 -*-
"""20230224quant_trading_binance_trade_all_new_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HP1Getq5uZ7SmrsTuTIICUIknsE5-Z-N
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 
# //jp 一天交易数据训练需要半小时，1000天的数据如何训练？-------暂时只针对大额交易预测
# //jp  取消小于100美元的交易+取消小数点后几位方便计算
# //jp  小数据测试，大数据最终训练---------多种模型训练如何比对？
# //jp  没有考虑交易量是否完成，原始算法直接分次买进，一次性卖出， 实际操作是否可以分次卖出，卖出比例原则，应对机制？？？
# //jp polo数据需要重新排序
# //jp 为什么很多当天交易是24000笔？
# //jp 研究架构设计，模式实际，优化实战？
# //jp 生成的low，high 造成无法盈利，------实测yahoo的nvdia数据没问题，可以盈利
# //jp 8。21    1。yahoo数据 low，high 数值改成等同close，看看是否能盈利。2。删除其他只保留close，date看看是否可以运行
#               3。试试其它模型    4。尝试直接对接polo开始买卖。
# //jp 股票data可以盈利，但是eth的data不行？？？为什么？------实验价格差距加大到5%，时间序列变成编号，
# eth变化只有千分之一，股票变化是5%,  实际交易是万分之2的变化



# 1405699200------------07/18/2014 @ 4:00pm (UTC)
# 1514800800------------01/01/2018 @ 10:00am (UTC)
# https://poloniex.com/public?command=returnChartData&currencyPair=USDT_BTC&start=1514800800&end=1514801800&period=300
# https://poloniex.com/public?command=returnChartData&currencyPair=USDT_BTC&start=1405699200&end=9999999999&period=14400


# 1.每5分钟更新数据
# 2.判断------借用以前代码很困难
# 3.买卖

!pip install chainer

from subprocess import check_output
import json
import time
import copy
import numpy as np
import pandas as pd
import chainer
import chainer.functions as F
import chainer.links as L
from plotly import tools
from plotly.graph_objs import *
from plotly.offline import init_notebook_mode, iplot, iplot_mpl



init_notebook_mode()

def code_step():
# 0:训练 1：加载model 2：买卖运行 3：aws买卖  4:back test whole history
    return 4
    

# if code_step()==4:
# backtest_csv=''

# !pip install plotly
# !pip install plotly --upgrade
# jp colab plotly  
def configure_plotly_browser_state():
  import IPython
  display(IPython.core.display.HTML('''
        <script src="/static/components/requirejs/require.js"></script>
        <script>
          requirejs.config({
            paths: {
              base: '/static/base',
              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',
            },
          });
        </script>
        '''))

import pandas

if code_step()!=3:   

    from google.colab import drive
    drive.mount("/content/drive", force_remount=True)





# jp setting
def per_money_aws():
    return 20.0

def max_buy_times():
    return 2
  
def per_buy_money():
    return 100


def train_length():
    # return 50
    return 100

def epoch_get():
    # return 16  
    # return 400*1
    return 40
    # return 280
# 400 200 极限
# 140 100  perday = -0.04


def only12(pact):
  
    # if pact==0:
    #    pact=1
    # # elif pact=1:
    return pact
     

  
def test_length():
    # return 200
      return -1

# times_total=0
# act_list_222=0

  
  

# def total_days(): 
#     return 10
def total_days(): 
    return 30



def backtest_filename():
    backtest_csv = '/content/drive/My Drive/code/quant trading/1/backtest_data.csv'
    return backtest_csv

# csv_name_model ='/content/drive/My Drive/code/quant trading/binance_BTCUSDT_5m_86400_3_2_15012019'

# csv_name_model ='/content/drive/My Drive/code/quant trading/binance_BTCUSDT_5m_86400_30_1_01122019'

csv_name_model ='/content/drive/My Drive/code/quant trading/binance_BTCUSDT_5m_86400_30_1_01122019'

# csv_name_model ='/content/drive/My Drive/code/quant trading/1/binance_BTCUSDT_15m_86400_30_24_22112019'

if code_step()==3: 
    
#     csv_name_model ='new_polo_300_USDT_BTC_14072019_30'
   csv_name_model ='binance_300_eth_usd_01032019_30' 



print('csv_name_model====',csv_name_model)

# dddqn_model ='/content/drive/My Drive/code/quant trading/right_quant_trading_2019-09-28_00:41:54.model'

# dddqn_model ='/content/drive/My Drive/code/quant trading/right_quant_trading_2019-09-28_00:41:54.model'

# dddqn_quant_trading_2020-02-05_22:56:06

# dddqn_model ='/content/drive/My Drive/code/quant trading/dddqn_quant_trading_2020-02-05_22:56:06.model'

# dddqn_quant_trading_2020-02-13_00:08:36
# dddqn_model ='/content/drive/My Drive/code/quant trading/dddqn_quant_trading_2020-02-13_00:08:36.model'
# dddqn_quant_trading_2020-02-13_00:08:36.model
# dddqn_quant_trading_2020-02-16_02:07:50
# dddqn_quant_trading_2020-02-17_02:53:05
# dddqn_quant_trading_2020-02-17_03:24:52
# backtest_save_list==== -0.014991226246799555 [0.37973945200136594, 0.3501349234112292, 0.11760912032290204, 0.05490100476302385, 0.03805654649087938, -0.5829643671991784, 0.003855675531928437, -0.2197054895907794, -0.021147956957976017, -0.019171767667475845, -0.23165448586859586, 0.019150699343397058, -0.010382800453189312, -0.0052785905591698525, -0.005488217156816436, -0.00447195124203777, 0.11263234847065581, 0.11562990761228534, 0.0027413888790911722, -0.17015888434744075, -0.27453782338132793, -0.0016620833333337742, -0.01571253540402049, 0.008096456411394315]


#成功模型 dddqn_quant_trading_2020-02-17_12:33:51
# backtest_save_list==== 0.03933160574666963 [0.2673137440758293, 0.33832262695017395, -0.6578935563807928, 0.13994825120327217, -0.1098088959064172, -0.3040623916807246, 0.11998216258879198, 0.11573325302450559, -0.04699427511434363, 0.0375047507244796, -0.4002329722276937, 0.21008725823078694, -0.06283280744420613, -0.008966986619553356, -0.013067510555195144, 0.07227530694145545, 0.18188455611800824, 0.11575649342187985, 0.31786305479177396, 0.10115293715340447, 0.06230305202297301, 0.08518741191937446, 0.28391347941299183, 0.09858959526929673]
# 2019。01----2019。06---回测
# backtest_save_list==== 0.08876859679417261 [-0.023933653286220023, -0.028867510555195142, 0.04990864027478879, 0.15711788945134156, 0.08808982675521318, 0.29029638812510733]
# 2019.07---2019.12---回测
# backtest_save_list==== 0.10182929515560808 [0.07825293715340444, 0.037036385356306344, 0.05875407858604112, 0.26341347941299176, 0.07168959526929669




# dddqn_quant_trading_2020-02-20_03:53:23
# 2019。01----2019。06---回测
# backtest_save_list==== 0.017193035860379468 [0.012657604878411317, 0.003499759290592494, 0.0334622253327939, 0.04874924508796567, 0.022123737951066848, -0.01733435737855343
# 2019.07---2019.12---回测
# backtest_save_list==== 0.0006533655829300398 [0.0011034731663906129, -0.002735855188935132, -0.004948488422811566, 0.00959694479193291, 0.0002507535680733748
# dddqn_model_core ='dddqn_quant_trading_2020-02-20_03:53:23.model'




#成功模型 dddqn_quant_trading_2020-02-17_12:33:51
# 2019。01----2019。06---回测
# backtest_save_list==== 0.1109574856830615 [-0.008966986619553356, -0.013067510555195144, 0.07227530694145545, 0.18188455611800824, 0.11575649342187985, 
# 2019.07---2019.12---回测
# backtest_save_list==== 0.1262292951556081 [0.10115293715340447, 0.06230305202297301, 0.08518741191937446, 0.28391347941299183, 0.09858959526929673]

# backtest_save_list==== 0.03933160574666963 [0.2673137440758293, 0.33832262695017395, -0.6578935563807928, 0.13994825120327217, -0.1098088959064172, -0.3040623916807246, 0.11998216258879198, 0.11573325302450559, -0.04699427511434363, 0.0375047507244796, -0.4002329722276937, 0.21008725823078694, -0.06283280744420613, -0.008966986619553356, -0.013067510555195144, 0.07227530694145545, 0.18188455611800824, 0.11575649342187985, 0.31786305479177396, 0.10115293715340447, 0.06230305202297301, 0.08518741191937446, 0.28391347941299183, 0.09858959526929673]
# dddqn_model ='/content/drive/My Drive/code/quant trading/dddqn_quant_trading_2020-02-17_12:33:51.model'

# dddqn_model_core='dddqn_quant_trading_2020-02-17_12:33:51.model'

# dddqn_model_core='dddqn_quant_trading_2020-03-27_21:29:21.model'

dddqn_model_core='dddqn_quant_trading_2020-03-27_21_29_21.model'

dddqn_model ='/content/drive/My Drive/code/quant trading/'+dddqn_model_core
 

if code_step()==3: 
        
#     dddqn_model ='right_quant_trading_2019-09-28_00:41:54.model'
#     dddqn_model ='dddqn_quant_trading_2020-02-17_12_33_51.model'
   dddqn_model =dddqn_model_core

   dddqn_model=dddqn_model.replace(":", "_")


data = pd.read_csv(csv_name_model)

def get_info(data_1):
  print(data_1.dtypes)       
  print(data_1.head())
  print(data_1.tail())
#   print(len(data_1.index))

  for col in data_1.columns: 
    print(col) 
    
get_info(data)

# polo_fee_buy=0.0015
# polo_fee_sell=0.0025
polo_fee_buy=0.00
polo_fee_sell=0.00

  
  
from chainer import serializers

from time import gmtime, strftime

time_str=strftime("%Y-%m-%d_%H:%M:%S", gmtime())  
exchanger_name='binance_'

def save_log(name,data_log):
    if code_step()==3:
        save_log_aws(name,data_log)
    else:
        save_log_colab(name,data_log)

def save_log_colab(name,data_log):


    data = {}
    data[name] = []

    data[name].append(str(data_log))



    json_filename ='/content/drive/My Drive/code/quant trading/json_'+exchanger_name+time_str

    if code_step()==3: 
        json_filename ='log_'+exchanger_name+time_str

    with open(json_filename, 'a') as outfile:
        outfile.write("\n")
        json.dump(data, outfile)


def save_log_aws(name,data_log):

    str_1='\n'+name+'\n'+str(data_log)+'\n'
    json_filename ='log_'+exchanger_name+time_str
    print('json_filename===',json_filename)
    line_prepender(json_filename,str_1)
        
        

def act_static(new_act_list,aaa,profit_list):
    
    old_profit=0

    act_list=[]
    
    buy_times=0
    sell_times=0
    for one in  new_act_list:
      if one!=0:
        if one==2:
           buy_times=0
           sell_times+=1
          #  if buy_times<=max_buy_times():
           if sell_times==1:
                 act_list.append(one)
  
        if one==1:
           buy_times+=1
           sell_times=0
        
        
           if buy_times<=max_buy_times():
              if sell_times<2:
              #  buy_times=0
    #         else:
                  act_list.append(one)
            # act_list.append(one)
  
    print('2020 10.22   new_act_list==', len(new_act_list), new_act_list)            
    print('10.22 act_list==',len(act_list),act_list)
    # print('len act_list==',len(act_list))

    act_list_static=[]
    number=0
    number2=0
    
    for one in  act_list:
#       if one!=2:
      if one==1:
        number=number+1
        # number2=0
    
      elif one==2:
        if number>0:
          # if number2==0:
          act_list_static.append(number)
          number=0

    print('act_list_static==', len(act_list_static),   act_list_static)
    
    len_num=len(act_list_static)
    print('2020 len_num==',len_num)

    df1 = pd.DataFrame(list(zip(act_list_static, profit_list)), 
                   columns =['number_buy', 'profit_this']) 
    
    new2=df1['profit_this']/df1['number_buy']
    
    
    df1 = pd.DataFrame(list(zip(act_list_static, profit_list,new2)), 
                   columns =['number_buy', 'profit_this','new2']) 
    
    df1=df1.sort_values(by=['number_buy'],ascending=False)
#     ascending=False
    print('df1====',df1)
    
    act_list_static.sort(reverse = True)
    print('act_list_static  sort==',act_list_static)

#     print('real_act_list  sum==',    sum(real_act_list))
    
    times_total=    sum(act_list_static)+len_num
    per_time_profit=0.0
    if times_total>0:
      per_time_profit=float(aaa)/times_total
    print('2020 times_total====',times_total)

    print('2020 profit_total====',aaa)
    print('per_time_profit====',per_time_profit)
#     print('percent profit actually====',(per_time_profit-0.001)*times_total)

    ppp_1=(per_time_profit-0.001)*times_total/total_days()
#     print('percent profit perday====',(per_time_profit-0.001)*times_total/total_days())
    print('percent profit perday====',ppp_1)
    print('2020 profit_list====',profit_list)
    
#     init_key=csv_name_model+'---epoch_get--'+str(epoch_get())+'-----train_length-----'+str(train_length())+'------test_length----'+str(test_length())+'------data_length----'+str(len(data))

    save_log('percent profit',per_time_profit)
#     save_log('init_key',init_key)
    save_log('act_list_static',act_list_static)
    save_log('act_list',act_list)
    save_log('len act_list',str(len(act_list)))
    save_log('percent profit perday',str(ppp_1))
    save_log('file name',csv_name_model)
    if code_step()==4:
      save_log('model name',dddqn_model_core)
    else:
      save_log('model name',dddqn_model_output)
    save_log('df1',df1)
    backtest_save_list.append(ppp_1)
    print('backtest_save_list=====run')
        
        
        
        
data

def line_prepender(filename, line):
  
#     filename ='/content/drive/My Drive/code/quant trading/json_test3'
    try:
      with open(filename, 'r+') as f:
        content = f.read()
        f.seek(0, 0)
        f.write(line.rstrip('\r\n') + '\n' + content)
    except:
      
      with open(filename, 'a') as f:
          f.seek(0, 0)
          f.write(line.rstrip('\r\n') + '\n' )


date_split = train_length()

train = data[:date_split]

test = data[date_split:test_length()]



# len(train), len(test)



class Environment1:
    
    def __init__(self, data, history_t=90):
        self.data = data
        self.history_t = history_t
        self.reset()
        
    def reset(self):
        self.t = 0
        self.done = False
        self.profits = 0

        self.profits = 0
        
        self.total_btc = 0.000
        self.total_usdt=10000.000
        # self.per_money=100
        # self.per_money=per_buy_money()
        
        self.act_list= []
      
        self.positions = []
        self.profit_list = []
        self.position_value = 0
        self.history = [0 for _ in range(self.history_t)]
        # print('self.history =====',len(self.history), self.history )
        return [self.position_value] + self.history # obs

    # def rules12(list_one):
          #  list_one
    def rules12(self,list_one):
        
        times_loop=12
        # if len(list_one)>times_loop and len(list_one)%times_loop==0 :
      
        if len(list_one)>times_loop :
           found_0=0
           found_1=0
           found_2=0
           for aaa in list_one[-times_loop:]:
             if aaa==0:
                found_0+=1
             if aaa==1:
                found_1+=1
             if aaa==2:
                found_2+=1
            # if (found_0>0 and found_1>0) and found_2>0:
            
           if found_0*found_1*found_2==0:
          #  if found_1*found_2==0:  
               return True
        return False

    def rules12_act(self,list_one,act):
        
        # times_loop=1000
        times_loop=20
        # if len(list_one)>times_loop and len(list_one)%times_loop==0 :
      
        if len(list_one)>times_loop :
           found_0=0
           found_1=0
           found_2=0
           for aaa in list_one[-times_loop:]:
             if aaa==0:
                found_0+=1
             if aaa==1:
                found_1+=1
             if aaa==2:
                found_2+=1
            # if (found_0>0 and found_1>0) and found_2>0:
            
          #  if found_0*found_1*found_2==0:
          # #  if found_1*found_2==0:  
          #      return True
           
           if found_0==0:
          #  if found_1*found_2==0:  
               return 0
           
           if found_1==0:
          #  if found_1*found_2==0:  
               return 1
           
           if found_2==0:
          #  if found_1*found_2==0:  
               return 2        
        return act
        
 

    def step(self, act):

        reward = 0
        profits=0
     
              # for p in self.positions:
              # # profits += (self.data.iloc[self.t, :]['Close']*(1-polo_fee_sell) - (1+polo_fee_buy)*self.data.iloc[self.t-1, :]['Close'])
              #   change_1= (self.data.iloc[self.t, :]['Close'] - self.data.iloc[self.t-1, :]['Close'])
              #   profits +=change_1*per_buy_money()/p

              # reward += profits
              # self.profits += profits
              # self.profit_list.append(profits)

        
        # act=self.rules12_act(self.act_list,act)
        
        # act = 0: stay, 1: buy, 2: sell
        if act == 1:
                if len(self.positions) <= max_buy_times():
                   self.positions.append(self.data.iloc[self.t, :]['Close'])
              
        elif act == 2: # sell
              for p in self.positions:
                change_1= (self.data.iloc[self.t, :]['Close'] - p)
                profits +=change_1*per_buy_money()/p

              reward += profits
              self.profits += profits
              self.profit_list.append(profits)

              self.positions = []
              # if reward<0.001
        
        # set next time
        self.t += 1
        self.position_value = 0
        for p in self.positions:
            self.position_value += (self.data.iloc[self.t, :]['Close'] - p)
        self.history.pop(0)
        self.history.append(self.data.iloc[self.t, :]['Close'] - self.data.iloc[(self.t-1), :]['Close'])
        


        self.act_list.append(act)
        
        
        
        # clipping reward
        if reward > 0:
            reward = 1
        elif reward < 0:
            reward = -1
        
        return [self.position_value] + self.history, reward, self.done ,self.profit_list# obs, reward, done

env = Environment1(train)

def plot_loss_reward(total_losses, total_rewards):

    figure = tools.make_subplots(rows=1, cols=2, subplot_titles=('loss', 'reward'), print_grid=False)
    figure.append_trace(Scatter(y=total_losses, mode='lines', line=dict(color='skyblue')), 1, 1)
    figure.append_trace(Scatter(y=total_rewards, mode='lines', line=dict(color='orange')), 1, 2)
    figure['layout']['xaxis1'].update(title='epoch')
    figure['layout']['xaxis2'].update(title='epoch')
    figure['layout'].update(height=400, width=900, showlegend=False)
    iplot(figure)

#@title

def plot_train_test_by_q(train_env, test_env, Q, algorithm_name):
    
    # train
    pobs = train_env.reset()
    train_acts = []
    train_rewards = []

    for _ in range(len(train_env.data)-1):
        
        pact = Q(np.array(pobs, dtype=np.float32).reshape(1, -1))
        # print('pact===1===',pobs,pact,pact.data)
        pact = np.argmax(pact.data)
        # print('pact===2===',pact)
        pact=only12(pact)
        train_acts.append(pact)
            
        obs, reward, done ,profit_list= train_env.step(pact)
        train_rewards.append(reward)

        pobs = obs
        
    train_profits = train_env.profits
    
    # test
    pobs = test_env.reset()
    test_acts = []
    test_rewards = []

    for _ in range(len(test_env.data)-1):
    
        pact = Q(np.array(pobs, dtype=np.float32).reshape(1, -1))
        pact = np.argmax(pact.data)
        pact=only12(pact)
        test_acts.append(pact)
            
        obs, reward, done ,profit_list= test_env.step(pact)
        test_rewards.append(reward)

        pobs = obs
        
    test_profits = test_env.profits
    
    # plot
    train_copy = train_env.data.copy()
    test_copy = test_env.data.copy()
    train_copy['act'] = train_acts + [np.nan]
    train_copy['reward'] = train_rewards + [np.nan]
    test_copy['act'] = test_acts + [np.nan]
    test_copy['reward'] = test_rewards + [np.nan]
    train0 = train_copy[train_copy['act'] == 0]
    train1 = train_copy[train_copy['act'] == 1]
    train2 = train_copy[train_copy['act'] == 2]
    test0 = test_copy[test_copy['act'] == 0]
    test1 = test_copy[test_copy['act'] == 1]
    test2 = test_copy[test_copy['act'] == 2]
#     act_color0, act_color1, act_color2 = 'gray', 'cyan', 'magenta'
    act_color0, act_color1, act_color2 = 'gray', 'red', 'yellow'

    data = [
        Candlestick(x=train0.index, open=train0['Open'], high=train0['High'], low=train0['Low'], close=train0['Close'], increasing=dict(line=dict(color=act_color0)), decreasing=dict(line=dict(color=act_color0))),
        Candlestick(x=train1.index, open=train1['Open'], high=train1['High'], low=train1['Low'], close=train1['Close'], increasing=dict(line=dict(color=act_color1)), decreasing=dict(line=dict(color=act_color1))),
        Candlestick(x=train2.index, open=train2['Open'], high=train2['High'], low=train2['Low'], close=train2['Close'], increasing=dict(line=dict(color=act_color2)), decreasing=dict(line=dict(color=act_color2))),
        Candlestick(x=test0.index, open=test0['Open'], high=test0['High'], low=test0['Low'], close=test0['Close'], increasing=dict(line=dict(color=act_color0)), decreasing=dict(line=dict(color=act_color0))),
        Candlestick(x=test1.index, open=test1['Open'], high=test1['High'], low=test1['Low'], close=test1['Close'], increasing=dict(line=dict(color=act_color1)), decreasing=dict(line=dict(color=act_color1))),
        Candlestick(x=test2.index, open=test2['Open'], high=test2['High'], low=test2['Low'], close=test2['Close'], increasing=dict(line=dict(color=act_color2)), decreasing=dict(line=dict(color=act_color2)))
    ]
    title = '{}: train s-reward {}, profits {}, test s-reward {}, profits {}'.format(
        algorithm_name,
        int(sum(train_rewards)),
        int(train_profits),
        int(sum(test_rewards)),

        int(test_profits)
#         (test_profits)
        
        
    )
    layout = {
        'title': title,
        'showlegend': False,
         'shapes': [
             {'x0': date_split, 'x1': date_split, 'y0': 0, 'y1': 1, 'xref': 'x', 'yref': 'paper', 'line': {'color': 'rgb(0,0,0)', 'width': 1}}
         ],
        'annotations': [
            {'x': date_split, 'y': 1.0, 'xref': 'x', 'yref': 'paper', 'showarrow': False, 'xanchor': 'left', 'text': ' test data'},
            {'x': date_split, 'y': 1.0, 'xref': 'x', 'yref': 'paper', 'showarrow': False, 'xanchor': 'right', 'text': 'train data '}
        ]
    }
    figure = Figure(data=data, layout=layout)
    iplot(figure)
    print('train_profits===',train_profits)   
    print('test_profits===',test_profits)    
#     print('test_profits===',test_profits/test_env.data['Close'][0])    
    # aaa=test_profits/test_env.data.iloc[0, :]['Close']
    aaa=test_profits/(max_buy_times()*per_buy_money())
    
    print('profit percent===',aaa,aaa/len(test_env.data))
#     self.data.iloc[self.t, :]['Close']
    print('train_rewards===',train_rewards)   
    print('test_rewards===',test_rewards)    
    print('data   len===',len(test_env.data))
    
    act_static(test_acts,aaa,test_env.profit_list)
    print('0202')

# Dueling Double DQN

class Q_Network(chainer.Chain):

    def __init__(self, input_size, hidden_size, output_size):
        super(Q_Network, self).__init__(
            fc1 = L.Linear(input_size, hidden_size),
            fc2 = L.Linear(hidden_size, hidden_size),
            fc3 = L.Linear(hidden_size, hidden_size//2),
            fc4 = L.Linear(hidden_size, hidden_size//2),
            state_value = L.Linear(hidden_size//2, 1),
            advantage_value = L.Linear(hidden_size//2, output_size)
        )
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size

    def __call__(self, x):
        h = F.relu(self.fc1(x))
        h = F.relu(self.fc2(h))
        hs = F.relu(self.fc3(h))
        ha = F.relu(self.fc4(h))
        state_value = self.state_value(hs)
        advantage_value = self.advantage_value(ha)
        advantage_mean = (F.sum(advantage_value, axis=1)/float(self.output_size)).reshape(-1, 1)
        q_value = F.concat([state_value for _ in range(self.output_size)], axis=1) + (advantage_value - F.concat([advantage_mean for _ in range(self.output_size)], axis=1))
        return q_value

    def reset(self):
        self.zerograds()
        
        
        
        
def train_dddqn(env):


    Q = Q_Network(input_size=env.history_t+1, hidden_size=100, output_size=3)
    Q_ast = copy.deepcopy(Q)
    optimizer = chainer.optimizers.Adam()
    optimizer.setup(Q)
    epoch_num = epoch_get()
#     epoch_num = 400
#     epoch_num = 200
#     epoch_num = 15
    step_max = len(env.data)-1
    memory_size = 200
    batch_size = 50
    epsilon = 1.0
    epsilon_decrease = 1e-3
    epsilon_min = 0.1
    start_reduce_epsilon = 200
    train_freq = 10
    update_q_freq = 20
    gamma = 0.97
    show_log_freq = 5

    
    
    memory = []
    total_step = 0
    total_rewards = []
    total_losses = []

    start = time.time()
    for epoch in range(epoch_num):

        pobs = env.reset()
        step = 0
        done = False
        total_reward = 0
        total_loss = 0

        while not done and step < step_max:

            pact = np.random.randint(3)
            # pact = np.random.randint(1,3)
            # pact = np.random.randint(2)
            if np.random.rand() > epsilon:
                pact = Q(np.array(pobs, dtype=np.float32).reshape(1, -1))
                pact = np.argmax(pact.data)
            pact=only12(pact)
            # print('pact=only12(pact)====',pact)
            # act
            obs, reward, done,aaa_no_use = env.step(pact)

            # add memory
            memory.append((pobs, pact, reward, obs, done))
            if len(memory) > memory_size:
                memory.pop(0)

            # train or update q
            if len(memory) == memory_size:
                if total_step % train_freq == 0:
                    shuffled_memory = np.random.permutation(memory)
                    memory_idx = range(len(shuffled_memory))
                    for i in memory_idx[::batch_size]:
                        batch = np.array(shuffled_memory[i:i+batch_size])
                        b_pobs = np.array(batch[:, 0].tolist(), dtype=np.float32).reshape(batch_size, -1)
                        b_pact = np.array(batch[:, 1].tolist(), dtype=np.int32)
                        b_reward = np.array(batch[:, 2].tolist(), dtype=np.int32)
                        b_obs = np.array(batch[:, 3].tolist(), dtype=np.float32).reshape(batch_size, -1)
                        b_done = np.array(batch[:, 4].tolist(), dtype=np.bool)

                        q = Q(b_pobs)
                        """ <<< DQN -> Double DQN
                        maxq = np.max(Q_ast(b_obs).data, axis=1)
                        === """
                        indices = np.argmax(q.data, axis=1)
                        maxqs = Q_ast(b_obs).data
                        """ >>> """
                        target = copy.deepcopy(q.data)
                        for j in range(batch_size):
                            """ <<< DQN -> Double DQN
                            target[j, b_pact[j]] = b_reward[j]+gamma*maxq[j]*(not b_done[j])
                            === """
                            target[j, b_pact[j]] = b_reward[j]+gamma*maxqs[j, indices[j]]*(not b_done[j])
                            """ >>> """
                        Q.reset()
                        loss = F.mean_squared_error(q, target)
                        total_loss += loss.data
                        loss.backward()
                        optimizer.update()

                if total_step % update_q_freq == 0:
                    Q_ast = copy.deepcopy(Q)

            # epsilon
            if epsilon > epsilon_min and total_step > start_reduce_epsilon:
                epsilon -= epsilon_decrease

            # next step
            total_reward += reward
            pobs = obs
            step += 1
            total_step += 1

        total_rewards.append(total_reward)
        total_losses.append(total_loss)

        if (epoch+1) % show_log_freq == 0:
            log_reward = sum(total_rewards[((epoch+1)-show_log_freq):])/show_log_freq
            log_loss = sum(total_losses[((epoch+1)-show_log_freq):])/show_log_freq
            elapsed_time = time.time()-start
            print('\t'.join(map(str, [epoch+1, epsilon, total_step, log_reward, log_loss, elapsed_time])))
            start = time.time()
            
    return Q, total_losses, total_rewards

#@title

if code_step()==0:
    
    Q, total_losses, total_rewards = train_dddqn(Environment1(train))
    
    configure_plotly_browser_state()

    plot_loss_reward(total_losses, total_rewards)

#@title
from chainer import serializers

from time import gmtime, strftime

time_str=strftime("%Y-%m-%d_%H:%M:%S", gmtime())  

# dddqn_model ='/content/drive/My Drive/code/quant trading/right_0.00276_quant_trading_'+time_str+'.model'
dddqn_model_output ='/content/drive/My Drive/code/quant trading/dddqn_quant_trading_'+time_str+'.model'
  
#  dddqn_quant_trading_2020-02-13_00:08:36

if code_step()==0:
    serializers.save_npz(dddqn_model_output, Q)
else:
    Q = Q_Network(input_size=env.history_t+1, hidden_size=100, output_size=3)
    serializers.load_npz(dddqn_model, Q)

time_str=strftime("%Y-%m-%d_%H:%M:%S", gmtime())  
time_str

#@title

def back_test_core(train_1,test_1):
   
    configure_plotly_browser_state()
    plot_train_test_by_q(Environment1(train_1), Environment1(test_1), Q, 'Dueling Double DQN')
  

# backtest_save_list
backtest_save_list=[]

def history_file():

    # csv_history_list_1 = [
    #                   'binance_BTCUSDT_5m_86400_30_12_01012019',
    #                   'binance_BTCUSDT_5m_86400_30_12_31012019',
    #                   ]



    # csv_history_list_1=[
    #                   'binance_BTCUSDT_5m_86400_30_12_01012018',
    #                   'binance_BTCUSDT_5m_86400_30_12_31012018',
    #                   'binance_BTCUSDT_5m_86400_30_12_02032018',
    #                   'binance_BTCUSDT_5m_86400_30_12_01042018',
    #                   'binance_BTCUSDT_5m_86400_30_12_01052018',
    #                   'binance_BTCUSDT_5m_86400_30_12_31052018',

    #                   'binance_BTCUSDT_5m_86400_30_12_30062018',
    #                   'binance_BTCUSDT_5m_86400_30_12_30072018',
    #                   'binance_BTCUSDT_5m_86400_30_12_29082018',
    #                   'binance_BTCUSDT_5m_86400_30_12_28092018',
    #                   'binance_BTCUSDT_5m_86400_30_12_28102018',
    #                   'binance_BTCUSDT_5m_86400_30_12_27112018',

    #                   'binance_BTCUSDT_5m_86400_30_12_01012019',
    #                   'binance_BTCUSDT_5m_86400_30_12_31012019',
    #                   'binance_BTCUSDT_5m_86400_30_12_02032019',
    #                   'binance_BTCUSDT_5m_86400_30_12_01042019',
    #                   'binance_BTCUSDT_5m_86400_30_12_01052019',
    #                   'binance_BTCUSDT_5m_86400_30_12_31052019',

    #                   'binance_BTCUSDT_5m_86400_30_12_30062019',
    #                   'binance_BTCUSDT_5m_86400_30_12_30072019',
    #                   'binance_BTCUSDT_5m_86400_30_12_29082019',
    #                   'binance_BTCUSDT_5m_86400_30_12_28092019',
    #                   'binance_BTCUSDT_5m_86400_30_12_28102019',
    #                   'binance_BTCUSDT_5m_86400_30_12_27112019',]



    csv_history_list_1=[
                      # 'binance_BTCUSDT_15m_86400_30_24_01012018',
                      # 'binance_BTCUSDT_15m_86400_30_24_31012018',
                      # 'binance_BTCUSDT_15m_86400_30_24_02032018',
                      # 'binance_BTCUSDT_15m_86400_30_24_01042018',
                      # 'binance_BTCUSDT_15m_86400_30_24_01052018',
                      # 'binance_BTCUSDT_15m_86400_30_24_31052018',

                      # 'binance_BTCUSDT_15m_86400_30_24_30062018',
                      # 'binance_BTCUSDT_15m_86400_30_24_30072018',
                      # 'binance_BTCUSDT_15m_86400_30_24_29082018',
                      # 'binance_BTCUSDT_15m_86400_30_24_28092018',
                      # 'binance_BTCUSDT_15m_86400_30_24_28102018',
                      # 'binance_BTCUSDT_15m_86400_30_24_27112018',

                      # 'binance_BTCUSDT_15m_86400_30_24_27122018',

                      # 'binance_BTCUSDT_15m_86400_30_24_26012019',
                      # 'binance_BTCUSDT_15m_86400_30_24_25022019',
                      # 'binance_BTCUSDT_15m_86400_30_24_27032019',
                      # 'binance_BTCUSDT_15m_86400_30_24_26042019',
                      # 'binance_BTCUSDT_15m_86400_30_24_26052019',
                      # 'binance_BTCUSDT_15m_86400_30_24_25062019',

                      # 'binance_BTCUSDT_15m_86400_30_24_25072019',
                      # 'binance_BTCUSDT_15m_86400_30_24_24082019',
                      'binance_BTCUSDT_15m_86400_30_24_23092019',
                      'binance_BTCUSDT_15m_86400_30_24_23102019',
                      'binance_BTCUSDT_15m_86400_30_24_22112019',
                      
                      ]


    return   csv_history_list_1

def backtest_whole_history():
    
    '''
     1.back test whole history, 
     2.save 'model name,data name,profit perday,act list,whole profit,whole act list' to csv
     3.draw chart
    '''



    path_core ='/content/drive/My Drive/code/quant trading/1/'

  
    csv_history_list = history_file()

    for n in csv_history_list:


      data = pd.read_csv(path_core+n)

      print(path_core+n)
      print('len(data)===',len(data))

      date_split = train_length()

      train_one = data[:date_split]

      test_one = data[date_split:test_length()]

      back_test_core(train_one,test_one)

    answer_backtest_save_list=str([sum(backtest_save_list)/len(backtest_save_list), backtest_save_list])
    
    print('backtest_save_list====',answer_backtest_save_list)
          
    save_log('backtest_save_list',answer_backtest_save_list)
    
    # print('backtest_save_list====',sum(backtest_save_list)/len(backtest_save_list), backtest_save_list,)


if code_step()<2:

    print(len(test))
    back_test_core(train,test)

if code_step()==4:
   backtest_whole_history()

# jp backtest answer                                                                                                                                                                                                                                                                                                


import matplotlib.pyplot as plt
from pandas import DataFrame

# import numpy as np
backtest_row_list=[]
def chart_backtest_list():
  print('backtest_save_list====',sum(backtest_save_list)/len(backtest_save_list), backtest_save_list,)

  backtest_row_list.append(sum(backtest_save_list)/len(backtest_save_list))
  backtest_row_list.append(backtest_save_list)

  # print(backtest_save_list)
  plt.plot(backtest_save_list)
  plt.show()

# backtest_save_list==== 0.01374428797500276 [0.00042369716221712635, 0.0022089929704387436, 0.0005255532845431992, 0.015091028482788668, 0.032604091210936555, 0.054173903183525336, 0.007828552427011356, 0.01400123314357576, 0.006948133802344585, 0.0182481892473958, 0.0023676788348755734, 0.010510401950380416]
# from pandas import DataFrame

# backtest_save_list_test= ['modright_quant_trading_2019-09-28_00:41:54.modelel_name',0.01374428797500276, [0.00042369716221712635, 0.0022089929704387436, 0.0005255532845431992, 0.015091028482788668, 0.032604091210936555, 0.054173903183525336, 0.007828552427011356, 0.01400123314357576, 0.006948133802344585, 0.0182481892473958, 0.0023676788348755734, 0.010510401950380416]]
def backtest_save_csv():
    
    # cars = {'model': backtest_save_list_test[0],
    #         'ave per': backtest_save_list_test[1],
    #         'history result': backtest_save_list_test[2:],
    #         'history file': history_file(),
            
    #         }

    per_score=sum(backtest_save_list)/len(backtest_save_list)
    
    cars = {'model': dddqn_model,
            'ave per': per_score,
            'history result': [backtest_save_list],
            'history file': [history_file()],
            
            }

    df = DataFrame(cars, columns= ['model', 'ave per','history result','history file'])

    # export_csv = df.to_csv(backtest_filename(), index = None, header=True) #Don't forget to add '.csv' at the end of the path
    export_csv = df.to_csv(backtest_filename(), mode='a', header=False, index = None)
    	
# Width of the display in characters. If set to None and pandas will correctly auto-detect the width.
    pd.set_option('display.width', None)
    pd.set_option('display.max_columns', None)
    print('write csv ok',df,df['history file'][0])
    



if code_step()==4:
   chart_backtest_list()
   backtest_save_csv()

# !ls /content/drive/My\ Drive/code/module/*.py

# !git clone https://github.com/ganggbang/tm_exchang.git
# !cat '/content/gdrive/My Drive/mylib.py'
import sys
sys.path.append('/content/drive/My Drive/code/module')

if code_step()==3:
    sys.path.append('module')

!pip install dateparser

# import uuid
# uuid.uuid4().hex

from binance.client import Client
from binance.enums import *
from binance.exceptions import BinanceAPIException
from time import sleep
from sys import exit



# api_key = 'gnU4ilhSMQVQiKPoFXGabIIrrT91p3p0ED7LrzzASuowqNpTiv66m0qnDYEwysP4'
# api_secret = 'cpoonV8JJGvRs11IcPlIt7AG2vA4cWRRM8I6Fgea7TwT3XXDG1FPhQBpQRy0xTHz'

# API Key:
# zhmIcZNoj9OR8u2E3cAA23k2AY1Xynrw7gNRM7iSP0p9Tj4FZTmdL2bpiG3oceHM
# Secret Key: For your security, your API Secret Key will only be displayed at the time it is created. If you lose this key, you will need to delete your API and set up a new one.
# xiblRUBYUtIYhyVEQz7oGtuKqCtMB3g8T0wV3Du05SfpwCKOh9FM0XxiZ1uP8L6Y

# jinpeng2019usa@gmail.com

api_key = 'zhmIcZNoj9OR8u2E3cAA23k2AY1Xynrw7gNRM7iSP0p9Tj4FZTmdL2bpiG3oceHM'
api_secret = 'xiblRUBYUtIYhyVEQz7oGtuKqCtMB3g8T0wV3Du05SfpwCKOh9FM0XxiZ1uP8L6Y'


client = Client(api_key, api_secret)
  
def decimal_formatter(number):
	return format(number, '.8f')

def find_quantity(total, price):
	quantity = float(total) / float(price)
	return quantity

def calculate_price_target(initial, percentage=1.1):
	target = (percentage * float(initial) / 100 ) + float(initial) + 0.00000001
	return decimal_formatter(target)

def calculate_profit_percentage(initial, final):
	percent = (float(final) - float(initial)) / float(initial) * 100
	return format(percent, '.2f')

def order_confirm(symbol):
	confirm = False
	seconds = 0
	while not confirm:
		orders = client.get_open_orders(symbol=symbol)
		sleep(1)
		seconds += 1
		if not orders:
			confirm = True
		if seconds == 120:
			print("It's been over 2 minutes since you have placed this order. Cancel? Y/N")
			cancel = input("> ")
			if cancel.lower() == "y":
				orderId = orders[0]['orderId']
				client.cancel_order(symbol=symbol, orderId=orderId)
				confirm = True
			else:
				print("Order not cancelling. Selling...")
		if seconds == 300:
			print("It's been over 5 minutes since you have placed the order. ")
			print("If you stop here, your order will be sold at market value.")
			cancel2 = input('Stop? Y/N > ')
			if cancel2.lower() == "y":
				orderId = orders[0]['orderId']
				client.cancel_order(symbol=symbol, orderId=orderId)
				quant = input("enter quantity: ")
				if "." in quant:
					quantity = float(quant)
				else:
					quantity = int(quant)
				client.order_market_sell(symbol=symbol, quantity=quantity)
				confirm = True
			else:
				print("Not cancelling. The program will run until the order is confirmed.")
	print("Order is confirmed!")


def margin_buy_sell(buy_sell):
    info = client.get_margin_asset(asset='BTC')
    print(info)
    # info = client.get_margin_symbol(symbol='BTCUSDT')
    info = client.get_margin_price_index(symbol='BTCUSDT')
    print(info)
    price_1=float(info['price'])
    print(info['price'])
    info = client.get_margin_account()
    print(info)
    # json_1 = json.loads(info)
    price_1=format(price_1,'.2f')

    side_buy_sell=SIDE_BUY
    if buy_sell=='sell':
       side_buy_sell=SIDE_SELL
      


    order = client.create_margin_order(
                                        symbol='BTCUSDT',
                                        # symbol='USDTBTC',
                                        # side=SIDE_SELL,
                                        side=side_buy_sell,
                                        type=ORDER_TYPE_LIMIT,
                                        timeInForce=TIME_IN_FORCE_GTC,
                                        quantity=0.014,
                                        price=price_1)
		 
    
def buy_sell_loop(type_name):
  
      sym="BTCUSDT"
    
      coin = sym[:-4]
      asset = sym[-4:]

      klines = client.get_historical_klines(sym, Client.KLINE_INTERVAL_1MINUTE, "1 min ago")
      print(klines)
      most_recent = klines.pop()
      last_closing = most_recent[4]

      balance = client.get_asset_balance(asset=asset)
      balance_coin = client.get_asset_balance(asset=coin)
      bitcoins = float(balance['free'])
      bitcoins_sell = float(balance_coin['free'])-0.0005

#       print('last_closing====',last_closing,1/float(last_closing))
      print('            balance_coin====',bitcoins_sell,balance_coin)
      print('buy_sell_loop 111===',per_money_aws(),last_closing)
#         
      number_of_coins_1=format((per_money_aws()*1/float(last_closing)),'.3f'  )
#         
      print('buy_sell_loop 2')
      number_of_coins_1_sell=format(bitcoins_sell,'.3f'  )
#         
      print('buy_sell_loop 3')
      print('number_of_coins_1_sell===',number_of_coins_1_sell)
#         
# //jp 0.0015 最小交易额度， 应该是10美元
      if type_name=='buy':
        client.order_limit_buy(symbol=sym, quantity=number_of_coins_1, price=last_closing)
      elif type_name=='sell':
        client.order_limit_sell(symbol=sym, quantity=number_of_coins_1_sell, price=last_closing)
        # create_margin_order

# 				from binance.enums import *
# order = client.create_margin_order(
#     symbol='BNBBTC',
#     side=SIDE_BUY,
#     type=ORDER_TYPE_LIMIT,
#     timeInForce=TIME_IN_FORCE_GTC,
#     quantity=100,
#     price='0.00001')
        
#       client.order_limit_buy(symbol=sym, quantity=number_of_coins_1, price=last_closing)
#       client.order_limit_sell(symbol=sym, quantity=number_of_coins_1, price=last_closing)
#       client.order_limit_sell(symbol=sym, quantity=number_of_coins_1, price=last_closing)

# buy_loop()

# buy_loop()

# buy_sell_loop('sell')


# act = 0: stay, 1: buy, 2: sell

def one_step(test_env, Q, algorithm_name):
    
    
    # test
    pobs = test_env.reset()
    test_acts = []
    test_rewards = []
#     print('len(test_env.data)========',len(test_env.data))

    for _ in range(len(test_env.data)-1):
#         print('asdf')
        pact = Q(np.array(pobs, dtype=np.float32).reshape(1, -1))
# #         print('len(pact.data)========',(pact.data))
        pact = np.argmax(pact.data)
# #         print('len(pact.data)========',pact)
        pact=only12(pact)
        test_acts.append(pact)
            
        obs, reward, done,aaa_add_act_list = test_env.step(pact)
        test_rewards.append(reward)

        pobs = obs
        
    test_profits = test_env.profits
    return test_profits,test_acts
  
  
          
act_list_static=[]     



def auto_step_new():
    test_1=test[0:3]
    pd.set_option('display.max_columns', 30)
    print(test_1)
    

#     new_profit,new_act_list=one_step(Environment1_today_try(test_1), Q, 'Dueling Double DQN')
    new_profit,new_act_list=one_step(Environment1(test_1), Q, 'Dueling Double DQN')
    print('new_act_list===',new_act_list)
#     one_step(Environment1_today(test_1), Q, 'Dueling Double DQN')



# csv_name_model ='/content/drive/My Drive/code/quant trading/new_polo_300_USDT_BTC_14072019_30'

def money_name():
    return 'BTCUSDT'

def loop_time():
    return '15m'
    
def per_length():
  # max json item 500
    return 60*60*24

def range_days_get():
    return 3

def how_many_month():
    return 2
   
def star_date():
    return '01012018'
   
def file_name_whole():
    
#     if code_step()==3:
#         return '/content/drive/My Drive/code/quant trading/binance_'+str(money_name())+'_'+loop_time()+'_'+str(per_length())+'_'+str(range_days_get())+'_'+str(how_many_month())+'_'
#     else:
        return '/content/drive/My Drive/code/quant trading/binance_'+str(money_name())+'_'+loop_time()+'_'+str(per_length())+'_'+str(range_days_get())+'_'+str(how_many_month())+'_'



print(file_name_whole())

def get_info(data_1):
    print(data_1.dtypes)       
    print(data_1.head())
    print(data_1.tail())
    print(len(data_1.index))

    for col in data_1.columns: 
      print(col) 
    
# get_info(data)

def stamptime_now():

  
  
    now_time=int(time.time())
#     now_time-=60*60*24*5
#     now_begin=now_time-300
    now_begin=now_time-1200
#     print((now_time))
#     print((now_begin))
    
    
    
    url='https://api.binance.com/api/v1/klines?interval='+loop_time()+'&limit=500&startTime='+str(now_begin*1000)+'&endTime='+str(now_time*1000)+'&symbol='+money_name()
#     print('url=============',url)
    df = pd.read_json(url, orient='columns')
#     print(df)
    return df
    

      

def new_name_pd(new):
#     new=new_data
    
    new.columns = ['Date','Open','High',  
                              'Low','Close','Volume','Time2',
                              'key1','key2','key3','key4','key5']

    new['Date'] = new['Date'].astype(np.int64)
    new['Time2'] = new['Time2'].astype(np.int64)

#     del new['key1']
#     del new['key2']
#     del new['key3']
#     del new['key4']
#     del new['key5']

#     del new['High']
#     del new['Low']
#     del new['Open']
#     list_all=list_all.append(new.iloc[-1])
# #     list_all=list_all.append(new.iloc[-1])
#     list_all['Date'] = list_all['Date'].astype(np.int64)
#     list_all['Time2'] =list_all['Time2'].astype(np.int64)
    
#     print('(new new)====',new)
#     print('Environment1(list_all Environment1(list_all))
#     new_profit,new_act_list=one_step(Environment1(list_all), Q, 'Dueling Double DQN')
#     print('new_act_list===',new_act_list)



#     print('list_all===',list_all)

#     print('Environment1(test), =======',Environment1(test))
    return new
# buy_sell
def buy_sell(list_act):
    if len(list_act)>0:

        if list_act[-1]==1:
           try:
             buy_sell_loop('buy')
           except:
             print('buy_sell_loop buy err')
    
           
#            try:
#              margin_buy_sell('buy')
#            except:
#              print('margin_buy_sell buy err')
             
        if list_act[-1]==2:
           try:
             buy_sell_loop('sell')
           except:
             print('buy_sell_loop sell err')
    
           
#            try:
#              margin_buy_sell('sell')
#            except:
#              print('margin_buy_sell sell err')
        
            
    
            
       



def loop_run():
    if code_step()==3:
        loop_run_aws()
    else:
        loop_run_colab()
  
def loop_run_colab():
  
    list_all=pd.DataFrame()
    
    while True:
      
      new=stamptime_now()
      
      new =new_name_pd(new)
#       print('new  date===',new.iloc[-1]['Date'])

#       list_all=list_all.append(new.iloc[-1])
      
      
      
      if len(list_all)==0:
         list_all=list_all.append(new.iloc[-1])

      if new.iloc[-1]['Date']!=list_all.iloc[-1]['Date']:
         print('run add')
         
         list_all=list_all.append(new.iloc[-1])
  
         new_profit,new_act_list=one_step(Environment1(list_all), Q, 'Dueling Double DQN')
         print('list_all===',list_all)
         print('new_act_list===',new_act_list)
#          action_polo(new_act_list)
         buy_sell(new_act_list)



      time.sleep(1)
        


def loop_run_aws():
  
    print('run loop_run_aws 1') 
    list_all=pd.DataFrame()
    
    while True:
      print('run loop_run_aws 2')  
#       save_log('running','per_time_profit')
      new=stamptime_now()
      if len(new)>0:
          new =new_name_pd(new)
        
          if len(list_all)==0:
             list_all=list_all.append(new.iloc[-1])

          if len(new)>0:
              if new.iloc[-1]['Date']!=list_all.iloc[-1]['Date']:
                 print('run add')

        #          save_log('running','per_time_profit')


                 list_all=list_all.append(new.iloc[-1])

                 new_profit,new_act_list=one_step(Environment1(list_all), Q, 'Dueling Double DQN')
                 print('list_all===',list_all)
                 print('new_act_list_2020===',new_act_list)
        #          action_polo(new_act_list)
        
                 try:
                   buy_sell(new_act_list)
                 except:
                   print('try err buy_sell')
                 
                 save_log('new_act_list',str(new_act_list))
                 save_log('len(new_act_list)',str(len(new_act_list)))



      time.sleep(5)
 
      

              
def loop_run_1():
  
    list_all=pd.DataFrame()
    
    while True:
      
      new=stamptime_now()
      
      new =new_name_pd(new)
      print('new  date===',new.iloc[-1]['Date'])

#       list_all=list_all.append(new.iloc[-1])
      
      
      
      if len(list_all)==0:
            list_all=list_all.append(new.iloc[-1])
#          list_all=list_all.append(new.iloc[-1])
#          print('list_all===',list_all)

#          new_profit,new_act_list=one_step(Environment1(list_all), Q, 'Dueling Double DQN')
#          print('new_act_list===',new_act_list)

      if new.iloc[-1]['Date']!=list_all.iloc[-1]['Date']:
         print('run add')
#       if True:
         list_all=list_all.append(new.iloc[-1])
#       list_all=list_all+new
#       print('new===',new)

#          df_old=df_lastone
#          df_all=df_all.append(df_old) 
         new_profit,new_act_list=one_step(Environment1(list_all), Q, 'Dueling Double DQN')
         print('new_act_list===',new_act_list)
#          action_polo(new_act_list)
         buy_sell(new_act_list)



#       if df_old.iloc[0]['Date']!=(df_lastone.iloc[0]['Date']) :
#          df_old=df_lastone
#          df_all=df_all.append(df_old) 
         
  
          
#          new_profit,new_act_list=one_step(Environment1(df_all), Q, 'Dueling Double DQN')
#          print('new_act_list===',new_act_list)
#          action_polo(new_act_list)
        
      print('list_all===',list_all)
      time.sleep(20)
  
  

      

def get_act(list_all,new):
#     new=new_data
    
    new.columns = ['Date','Open','High',  
                              'Low','Close','Volume','Time2',
                              'key1','key2','key3','key4','key5']

    new['Date'] = new['Date'].astype(np.int64)
    new['Time2'] = new['Time2'].astype(np.int64)

    del new['key1']
    del new['key2']
    del new['key3']
    del new['key4']
    del new['key5']

    del new['High']
    del new['Low']
    del new['Open']
    list_all=list_all.append(new.iloc[-1])
#     list_all=list_all.append(new.iloc[-1])
    list_all['Date'] = list_all['Date'].astype(np.int64)
    list_all['Time2'] =list_all['Time2'].astype(np.int64)
    
    print('(list_all)====',(list_all))
#     print('Environment1(list_all Environment1(list_all))
    new_profit,new_act_list=one_step(Environment1(list_all), Q, 'Dueling Double DQN')
    print('new_act_list===',new_act_list)



    print('list_all===',list_all)

    print('Environment1(test), =======',Environment1(test))




'''
jp pseudocode Get( act answer)--------input(new data)-------data into model---
    
'''    



def loop_run_new():
  
    list_all=pd.DataFrame()
    
    while True:
      
      new=stamptime_now()
      
#       print('new===',new.iloc[-1][0])
      act=get_act(list_all,new)
      
      time.sleep(1)
      
      
      
# loop_run()

# buy_sell_loop('buy')    

# Unnamed: 0      int64
# Date            int64
# Open          float64
# High          float64
# Low           float64
# Close         float64
# Volume        float64
# Time2           int64
# key1          float64
# key2            int64
# key3          float64
# key4          float64
# key5            int64

# list_all=pd.DataFrame()
# print('list_all===',list_all)
# new_profit,new_act_list=one_step(Environment1(list_all), Q, 'Dueling Double DQN')
# print('new_act_list===',new_act_list)

'''

jp func thread ok 线程监控完成

'''



from threading import Thread
import time

def stamptime_now_2():

  
  
    now_time=int(time.time())
    now_begin=now_time-1200
    num=3
    while True:
      num-=1
      if num<0:
        break
  #     url='https://api.binance.com/api/v1/klines?interval='+loop_time()+'&limit=500&startTime='+str(now_begin*1000)+'&endTime='+str(now_time*1000)+'&symbol='+money_name()
      url=''

      df=df = pd.DataFrame()

      try:
          df = pd.read_json(url, orient='columns')
      except:
          print('err')
  #     return df
      time.sleep(1)
  

# loop_run()

def run_0107():
    # Create and launch a thread

    t = Thread(target=loop_run, args=())
    t.start()
    while True:
      if t.is_alive():
          print('Still running')
      else:
          print('Completed')
          t = Thread(target=loop_run, args=())
          t.start()
      time.sleep(1)

if code_step()==3:      
    run_0107()

# print('12345')
# loop_run()
# loop_run_aws()

